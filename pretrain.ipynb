{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from player import NetworkPlayer\n",
    "from environments.Connect4.Network import CNN, ViT, CNN_old\n",
    "from environments.Connect4.env_cython import Env\n",
    "from policy_value_net import PolicyValueNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import NAdam\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, state_dim, capacity, action_dim, row, col, device='cpu'):\n",
    "        self.state = torch.full(\n",
    "            (capacity, state_dim, row, col), torch.nan, dtype=torch.float32, device=device)\n",
    "        self.mask = torch.full((capacity, action_dim), torch.nan, dtype=torch.bool, device=device)\n",
    "        self.count = 0\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.count, len(self.state))\n",
    "\n",
    "    def is_full(self):\n",
    "        return self.__len__() >= len(self.state)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = torch.full_like(\n",
    "            self.state, torch.nan, dtype=torch.float32)\n",
    "        self.mask = torch.full_like(self.mask, torch.nan, dtype=torch.bool)\n",
    "        self.count = 0\n",
    "\n",
    "    def to(self, device='cpu'):\n",
    "        self.state = self.state.to(device)\n",
    "        self.mask = self.mask.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def store(self, state, mask):\n",
    "        idx = self.count % len(self.state)\n",
    "        self.count += 1\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.from_numpy(state).type(\n",
    "                torch.FloatTensor).to(self.device)\n",
    "        self.state[idx] = state\n",
    "        if isinstance(mask, list):\n",
    "            mask = torch.tensor(mask, dtype=torch.bool, device=self.device)\n",
    "        self.mask[idx] = mask\n",
    "        return idx\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        idx = torch.from_numpy(np.random.randint(\n",
    "            0, self.__len__(), batch_size, dtype=np.int64))\n",
    "        return self.state[idx], self.mask[idx]\n",
    "\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def start_self_play(self, player, first_n_steps=5):\n",
    "        self.env.reset()\n",
    "        states,  masks = [], []\n",
    "        steps = 0\n",
    "        while True:\n",
    "            if steps < first_n_steps:\n",
    "                action, _ = player.get_action(self.env)\n",
    "            else:\n",
    "                action, _ = player.get_action(self.env)\n",
    "            steps += 1\n",
    "            states.append(self.env.current_state())\n",
    "            masks.append(self.env.valid_mask())\n",
    "            self.env.step(action)\n",
    "            if self.env.done():\n",
    "                return states, masks\n",
    "\n",
    "\n",
    "def instant_augment(state_original, mask_original=None):\n",
    "    state, mask = deepcopy(state_original), deepcopy(mask_original)\n",
    "    for idx, i in enumerate(state):\n",
    "        for idx_j, j in enumerate(i):\n",
    "            state[idx, idx_j] = torch.fliplr(j)\n",
    "        if mask_original is not None:\n",
    "            mask[[idx]] = torch.fliplr(mask[[idx]])\n",
    "    state = torch.concat([state, state_original])\n",
    "    if mask_original is not None:\n",
    "        mask = torch.concat([mask, mask_original])\n",
    "    return state, mask\n",
    "\n",
    "\n",
    "def quantile_huber_loss(pred, target, tau, kappa=1.0):\n",
    "    assert pred.shape[1] == tau.shape[0], \"pred and tau must have compatible shapes\"\n",
    "    target = target.expand_as(pred)\n",
    "    diff = target - pred\n",
    "    huber = torch.where(diff.abs() <= kappa, 0.5 * diff.pow(2), kappa * (diff.abs() - 0.5 * kappa))\n",
    "    tau = tau.view(1, -1)\n",
    "    loss = torch.abs(tau - (diff.detach() < 0).float()) * huber\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load parameters.\n",
      "Error(s) in loading state_dict for CNN:\n",
      "\tMissing key(s) in state_dict: \"hidden.5.weight\", \"hidden.5.bias\", \"hidden.5.running_mean\", \"hidden.5.running_var\", \"hidden.8.weight\", \"hidden.8.bias\", \"hidden.9.weight\", \"hidden.9.bias\", \"hidden.9.running_mean\", \"hidden.9.running_var\", \"policy_head.1.weight\", \"policy_head.1.bias\", \"policy_head.4.weight\", \"policy_head.4.bias\", \"value_head.4.weight\", \"value_head.4.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"hidden.3.weight\", \"hidden.3.bias\", \"hidden.4.running_mean\", \"hidden.4.running_var\", \"hidden.4.num_batches_tracked\", \"hidden.6.weight\", \"hidden.6.bias\", \"hidden.7.weight\", \"hidden.7.bias\", \"hidden.7.running_mean\", \"hidden.7.running_var\", \"hidden.7.num_batches_tracked\", \"value_head.1.running_mean\", \"value_head.1.running_var\", \"value_head.1.num_batches_tracked\", \"value_head.3.weight\", \"value_head.3.bias\". \n",
      "\tsize mismatch for hidden.4.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([128, 64, 4, 5]).\n",
      "\tsize mismatch for policy_head.0.weight: copying a param with shape torch.Size([7, 256]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n",
      "\tsize mismatch for policy_head.0.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([256]).\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "game = Game(Env())\n",
    "buffer = ReplayBuffer(3, 100000, 7, 6, 7, device=device)\n",
    "\n",
    "teacher_net = CNN(0, device=device)\n",
    "teacher_policy = PolicyValueNet(teacher_net, 0.99, './params/AZ2_Connect4_CNN_best.pt')\n",
    "teacher_player = NetworkPlayer(teacher_policy, False)\n",
    "teacher_player.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2000, num_example: 42894"
     ]
    }
   ],
   "source": [
    "plt.ion()\n",
    "epoch = 0\n",
    "while epoch < 2000:\n",
    "    epoch += 1\n",
    "    states, masks = game.start_self_play(teacher_player, first_n_steps=0)\n",
    "    for i in range(len(states)):\n",
    "        buffer.store(states[i], masks[i])\n",
    "    print(f'\\repoch: {epoch}, num_example: {buffer.__len__()}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretrain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.student = CNN(0, device=device)\n",
    "        self.encoder = self.student.hidden\n",
    "        self.decoder = nn.Sequential(nn.Linear(64 * 4, 64 * 4),\n",
    "                                     nn.BatchNorm1d(64 * 4),\n",
    "                                     nn.SiLU(True),\n",
    "                                     nn.Linear(64 * 4, 42 * 2),\n",
    "                                     nn.Sigmoid())\n",
    "        self.opt = NAdam(self.parameters(), lr=1e-3, weight_decay=0.01, decoupled_weight_decay=True)\n",
    "        self.device = device\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def save(self):\n",
    "        torch.save(self.encoder.state_dict(), 'CNN_pretrained.pt')\n",
    "    \n",
    "    def forward(self, state):\n",
    "        laten = self.encoder(state)\n",
    "        dec = self.decoder(laten)\n",
    "        return dec.view(-1, 2, 6, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = Pretrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for j in tqdm(range(100000)):\n",
    "    mask = None\n",
    "    state, mask = buffer.sample(256)\n",
    "    state, mask = instant_augment(state, mask)\n",
    "    pt.opt.zero_grad()\n",
    "    state_pred = pt(state)\n",
    "    loss = F.binary_cross_entropy(state_pred, state[:, :-1])\n",
    "    loss.backward()\n",
    "    pt.opt.step()\n",
    "    losses.append(loss.item())\n",
    "    if j % 20 == 0 and j != 0:\n",
    "        plt.clf()\n",
    "        plt.plot(losses, label='P Loss', alpha=0.5)\n",
    "        plt.legend()\n",
    "        plt.title(f'P Loss: {losses[-1]: .5f}')\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.1)\n",
    "        pt.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
